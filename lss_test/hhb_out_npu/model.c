/* auto generate by HHB_VERSION 2.6.0 */

#include <shl_pnna.h>

void *csinn_(char *params_base) {
  struct csinn_session *sess = csinn_alloc_session();
  sess->base_run_mode = CSINN_RM_NPU_GRAPH;
  sess->base_quant_type = CSINN_QUANT_INT8_ASYM;
  sess->model.priority = 0;
  sess->base_api = CSINN_TH1520;
  sess->base_dtype = CSINN_DTYPE_INT8;
  csinn_session_init(sess);
  csinn_set_input_number(1, sess);
  csinn_set_output_number(1, sess);

  struct csinn_tensor *input = csinn_alloc_tensor(sess);
  input->name = "input@@conv2d_/conv1/Conv_PART_0_1_fuse_bias_add_/conv1/Conv_2_0";
  input->dtype = CSINN_DTYPE_INT8;
  input->layout = CSINN_LAYOUT_NCHW;
  input->dim[0] = 1;
  input->dim[1] = 3;
  input->dim[2] = 224;
  input->dim[3] = 224;
  input->dim_count = 4;
  input->qinfo = (struct csinn_quant_info *)(params_base + 0);
  input->quant_channel = 1;
  struct csinn_tensor *output_0 = csinn_alloc_tensor(sess);
  output_0->name = "output_0";
  output_0->dtype = CSINN_DTYPE_INT8;
  output_0->layout = CSINN_LAYOUT_NCHW;
  output_0->dim[0] = 1;
  output_0->dim[1] = 1;
  output_0->dim[2] = 111;
  output_0->dim[3] = 111;
  output_0->dim_count = 4;
  output_0->qinfo = (struct csinn_quant_info *)(params_base + 24);
  output_0->quant_channel = 1;
  struct csinn_tensor *kernel_0 = csinn_alloc_tensor(sess);
  kernel_0->name = "kernel_0";
  kernel_0->data = params_base + 72;
  kernel_0->is_const = 1;
  kernel_0->dtype = CSINN_DTYPE_INT8;
  kernel_0->layout = CSINN_LAYOUT_OIHW;
  kernel_0->dim[0] = 1;
  kernel_0->dim[1] = 3;
  kernel_0->dim[2] = 3;
  kernel_0->dim[3] = 3;
  kernel_0->dim_count = 4;
  kernel_0->qinfo = (struct csinn_quant_info *)(params_base + 48);
  kernel_0->quant_channel = 1;
  struct csinn_tensor *bias_0 = csinn_alloc_tensor(sess);
  bias_0->name = "bias_0";
  bias_0->data = params_base + 123;
  bias_0->is_const = 1;
  bias_0->dtype = CSINN_DTYPE_INT32;
  bias_0->layout = CSINN_LAYOUT_O;
  bias_0->dim[0] = 1;
  bias_0->dim_count = 1;
  bias_0->qinfo = (struct csinn_quant_info *)(params_base + 99);
  bias_0->quant_channel = 1;
  struct csinn_conv2d_params *params_0 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_0->group = 1;
  params_0->stride_height = 2;
  params_0->stride_width = 2;
  params_0->dilation_height = 1;
  params_0->dilation_width = 1;
  params_0->conv_extra.kernel_tm = NULL;
  params_0->conv_extra.conv_mode = CSINN_DIRECT;
  params_0->pad_top = 0;
  params_0->pad_left = 0;
  params_0->pad_down = 0;
  params_0->pad_right = 0;
  params_0->base.name = "conv2d_/conv1/Conv_PART_0_1_fuse_bias_add_/conv1/Conv_2";
  params_0->base.quant_type = CSINN_QUANT_INT8_ASYM;
  csinn_conv2d_init(input, output_0, kernel_0, bias_0, params_0);
  int32_t *shape_1 = malloc(2 * 4);
  shape_1[0] = 1;
  shape_1[1] = -1;
  struct csinn_tensor *output_1 = csinn_alloc_tensor(sess);
  output_1->name = "output_1";
  output_1->dtype = CSINN_DTYPE_INT8;
  output_1->layout = CSINN_LAYOUT_NC;
  output_1->dim[0] = 1;
  output_1->dim[1] = 12321;
  output_1->dim_count = 2;
  output_1->qinfo = (struct csinn_quant_info *)(params_base + 128);
  output_1->quant_channel = 1;
  struct csinn_reshape_params *params_1 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_1->shape = shape_1;
  params_1->shape_num = 2;
  params_1->base.name = "reshape_/Reshape_3";
  params_1->base.quant_type = CSINN_QUANT_INT8_ASYM;
  csinn_reshape_init(output_0, output_1, params_1);
  struct csinn_tensor *output_2 = csinn_alloc_tensor(sess);
  output_2->name = "dense_/linear/Gemm_PART_0_4_fuse_add_output@@/linear/Gemm_5_2";
  output_2->dtype = CSINN_DTYPE_INT8;
  output_2->layout = CSINN_LAYOUT_NC;
  output_2->dim[0] = 1;
  output_2->dim[1] = 32;
  output_2->dim_count = 2;
  output_2->qinfo = (struct csinn_quant_info *)(params_base + 152);
  output_2->quant_channel = 1;
  struct csinn_tensor *kernel_2 = csinn_alloc_tensor(sess);
  kernel_2->name = "kernel_2";
  kernel_2->data = params_base + 200;
  kernel_2->is_const = 1;
  kernel_2->dtype = CSINN_DTYPE_INT8;
  kernel_2->layout = CSINN_LAYOUT_OI;
  kernel_2->dim[0] = 32;
  kernel_2->dim[1] = 12321;
  kernel_2->dim_count = 2;
  kernel_2->qinfo = (struct csinn_quant_info *)(params_base + 176);
  kernel_2->quant_channel = 1;
  struct csinn_tensor *bias_2 = csinn_alloc_tensor(sess);
  bias_2->name = "bias_2";
  bias_2->data = params_base + 394496;
  bias_2->is_const = 1;
  bias_2->dtype = CSINN_DTYPE_INT32;
  bias_2->layout = CSINN_LAYOUT_O;
  bias_2->dim[0] = 32;
  bias_2->dim_count = 1;
  bias_2->qinfo = (struct csinn_quant_info *)(params_base + 394472);
  bias_2->quant_channel = 1;
  struct csinn_fc_params *params_2 = csinn_alloc_params(sizeof(struct csinn_fc_params), sess);
  params_2->units = 32;
  params_2->base.name = "dense_/linear/Gemm_PART_0_4_fuse_add_output@@/linear/Gemm_5";
  params_2->base.quant_type = CSINN_QUANT_INT8_ASYM;
  csinn_fullyconnected_init(output_1, output_2, kernel_2, bias_2, params_2);
  input->mtype = CSINN_MEM_TYPE_CPU_NOT_ALIGNED;
  csinn_set_tensor_entry(input, sess);
  csinn_set_input(0, input, sess);

  csinn_conv2d(input, output_0, kernel_0, bias_0, params_0);
  csinn_reshape(output_0, output_1, params_1);
  csinn_fullyconnected(output_1, output_2, kernel_2, bias_2, params_2);
  csinn_set_output(0, output_2, sess);

  csinn_session_setup(sess);
  return sess;
}
void csinn_update_input_and_run(struct csinn_tensor **input_tensors , void *sess) {
  csinn_update_input(0, input_tensors[0], sess);
  csinn_session_run(sess);
}
